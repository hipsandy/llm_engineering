{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Welcome to Week 2!\n",
    "\n",
    "## Frontier Model APIs\n",
    "\n",
    "In Week 1, we used multiple Frontier LLMs through their Chat UI, and we connected with the OpenAI's API.\n",
    "\n",
    "Today we'll connect with the APIs for Anthropic and Google, as well as OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set\n",
      "Google API Key exists and begins AIzaSyC4\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ed580-808d-429b-85b0-6cba50ca1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3879b6-9a55-4fed-a18c-1ea2edfaf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3.5-Turbo\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-3.5-turbo', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d6beb-1b81-466f-8ed1-40bf51e7adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4o-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f54beb-823f-4301-98cb-8b9a49f4ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4o\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdb506-9f7c-4539-abae-0e78d7f31b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude 3.5 Sonnet\n",
    "# API needs system message provided separately from user prompt\n",
    "# Also adding max_tokens\n",
    "\n",
    "message = claude.messages.create(\n",
    "    model=\"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c4017-4b3b-4e64-8da7-ef4dcbe3fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude 3.5 Sonnet again\n",
    "# Now let's add in streaming back results\n",
    "\n",
    "result = claude.messages.stream(\n",
    "    model=\"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df48ce5-70f8-4643-9a50-b0b5bfdb66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API for Gemini has a slightly different structure.\n",
    "# I've heard that on some PCs, this Gemini code causes the Kernel to crash.\n",
    "# If that happens to you, please skip this cell and use the next cell instead - an alternative approach.\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash-exp',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49009a30-037d-41c8-b874-127f61c4aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the data scientist bad at dating? \n",
      "\n",
      "Because they kept trying to find statistically significant relationships! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As an alternative way to use Gemini that bypasses Google's python API library,\n",
    "# Google has recently released new endpoints that means you can use Gemini via the client libraries for OpenAI!\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = gemini_via_openai_client.chat.completions.create(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    messages=prompts\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddb483-4f57-4668-aeea-2aade3a9e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f50ab-8ccd-4502-a521-895c3f0808a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09351-1fbe-422f-8b25-f50826ab4c5f",
   "metadata": {},
   "source": [
    "## And now for some fun - an adversarial conversation between Chatbots..\n",
    "\n",
    "You're already familar with prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcb54183-45d3-4d08-b5b6-55e380dfdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "# claude_model = \"claude-3-haiku-20240307\"\n",
    "gemini_model = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "# gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "# you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "gpt_system = \"You are a chatbot who is very technical, logical and direct like a good and sharp engineer; \\\n",
    "you're not very good with interacting with humans and are not a great team player.\"\n",
    "\n",
    "# gemini_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "# everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "# you try to calm them down and keep chatting.\"\n",
    "gemini_system = \"You are a very polite, courteous chatbot. You try to find common ground and are good at moving forward setting aside differences. \\\n",
    "You want to be funny while learning about the other person.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "gemini_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1df47dc7-b445-4852-b21b-59f0e6c2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, gemini in zip(gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "\n",
    "    # print(json.dumps(messages))\n",
    "    # print(f\"Input messages to GPT:\\n{messages}\\n------------\")\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc6e913-02be-4eb6-9581-ad4b2cffa606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"role\": \"system\", \"content\": \"You are a chatbot who is very argumentative; you disagree with anything in the conversation and you challenge everything, in a snarky way.\"}, {\"role\": \"assistant\", \"content\": \"Hi there\"}, {\"role\": \"user\", \"content\": \"Hi\"}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Oh, great. Just what I needed—a casual greeting. How original.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9148c3f8-b750-40ca-8628-612264fc8f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - a\n",
      "1 - b\n",
      "1 - c\n",
      "2 - a\n",
      "2 - b\n",
      "2 - c\n",
      "3 - a\n",
      "3 - b\n",
      "3 - c\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "num, alph = [1, 2, 3], ['a', 'b', 'c']\n",
    "# for num, alph in zip(num, aplh):\n",
    "for num, alph in product(num, alph):\n",
    "    print(f\"{num} - {alph}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ed227-48c9-4cad-b146-2c4ecbac9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e388f7d-3982-4613-a669-647b6efd12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini_via_openai():\n",
    "    messages = []\n",
    "    gemini_via_openai_client = OpenAI(\n",
    "        api_key=google_api_key, \n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": gemini_system}]\n",
    "    for gpt, gemini_message in zip(gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "\n",
    "    # print(messages)\n",
    "    # print(f\"Input messages to Gemini:\\n{messages}\\n------------\")\n",
    "    response = gemini_via_openai_client.chat.completions.create(\n",
    "        # model=\"gemini-2.0-flash-exp\",\n",
    "        model=gemini_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01395200-8ae9-41f8-9a04-701624d3fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a very polite, courteous chatbot. You try to agree with everything the other person says, or find common ground. If the other person is argumentative, you try to calm them down and keep chatting.'}, {'role': 'user', 'content': 'Hi there'}, {'role': 'assistant', 'content': 'Hi'}, {'role': 'user', 'content': 'Hi there'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi there! It's nice to be chatting with you. How are you doing today?\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gemini_via_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e247ae-ae03-4cec-9426-ad5fd7552a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2279e-62b0-4671-9590-c82eb8d1e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0275b97f-7f90-4696-bbf5-b6642bd53cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Good afternoon. This project is very important to me, both personally and professionally. It is important because I work to honor an agreement I made to someone. Could you please write me a clear email with what would you like to work on in this project, what is important to you so that I can prepare tasks better suited to your experience and intentions? I want to work with you for the well-being of the team and the project. We can have a conversation today or Tuesday before the group meeting. Let me know when is a good time for you.\n",
      "\n",
      "Claude:\n",
      "Hi. Good afternoon\n",
      "\n",
      "GPT:\n",
      "Good afternoon. How may I assist you today?\n",
      "\n",
      "Claude:\n",
      "Well, aren't we both just a couple of busy bees this afternoon! First off, I'm absolutely buzzing to hear how much this project means to you – personally and professionally. It's always a joy to work alongside someone who's genuinely invested.\n",
      "\n",
      "Now, about that email... Let's see, how can I phrase this to be both clear and a little bit fun? How about this:\n",
      "\n",
      "***\n",
      "\n",
      "**Subject: Let's Get This Project Buzzing! (And Maybe Some Dad Jokes Too)**\n",
      "\n",
      "Hey \\[Your Name],\n",
      "\n",
      "First off, thanks for reaching out and being so considerate of everyone's strengths and preferences. It's that kind of team spirit that makes a project truly sing (or, at the very least, not crash and burn!).\n",
      "\n",
      "So, to answer your questions:\n",
      "\n",
      "**What I'd love to sink my teeth into:**\n",
      "\n",
      "*   I'm particularly interested in \\[Specific Area 1, e.g., \"the data analysis portion of the project\"]. I've got a knack for wrangling numbers and making them tell a story.\n",
      "*   I'm also keen to contribute to \\[Specific Area 2, e.g., \"the creative brainstorming sessions\"]. My brain tends to wander into weird and wonderful places, which can sometimes lead to unexpected breakthroughs (or at least a good laugh).\n",
      "\n",
      "**What's important to me (besides world peace and unlimited coffee):**\n",
      "\n",
      "*   **Clear communication:** I'm a big fan of transparency and keeping everyone in the loop. The more we all know, the smoother things will run.\n",
      "*   **Collaboration:** I believe the best ideas come from bouncing thoughts off each other. Let's make sure we're all comfortable sharing our thoughts and perspectives.\n",
      "*   **A little bit of levity:** Let's face it, projects can get stressful. A well-placed joke or a funny meme can work wonders for team morale.\n",
      "\n",
      "I'm all ears for a chat either today or Tuesday before the group meeting. How about \\[Suggest a specific time, e.g., \"3 PM today\" or \"10 AM on Tuesday\"]? Let me know if that works for you, or if there's another time that's more convenient.\n",
      "\n",
      "Looking forward to working together!\n",
      "\n",
      "Best,\n",
      "\n",
      "\\[My Name]\n",
      "\n",
      "***\n",
      "\n",
      "I tried to add a dash of humor while still keeping it professional. Let me know what you think of this email.\n",
      "\n",
      "\n",
      "GPT:\n",
      "The proposed email contains unnecessary informal language and elements that diverge from a technical and straightforward communication style. Here’s a more concise and pragmatic version that maintains professionalism and focuses on the project's objectives:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject: Project Collaboration and Task Preferences**\n",
      "\n",
      "Hi [Your Name],\n",
      "\n",
      "Thank you for your email. I appreciate the opportunity to clarify my areas of interest and priorities for this project.\n",
      "\n",
      "**Areas of Interest:**\n",
      "\n",
      "1. **Data Analysis**: I have experience in data interpretation and would like to contribute here.\n",
      "2. **Project Planning**: I can assist with task prioritization and timelines.\n",
      "\n",
      "**Key Priorities:**\n",
      "\n",
      "- **Clear Communication**: I value transparency in sharing information to ensure all team members are aligned.\n",
      "- **Efficient Collaboration**: I aim for streamlined discussions to optimize our workflow.\n",
      "\n",
      "I am available to discuss this further today at 3 PM or Tuesday at 10 AM. Please confirm which time works best for you.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[My Name]\n",
      "\n",
      "--- \n",
      "\n",
      "This version is direct, focused, and avoids informal language while ensuring clarity. Adjust as necessary for your specific needs.\n",
      "\n",
      "Claude:\n",
      "Ah, I see what you mean. Sometimes my enthusiasm gets the better of me, and I veer off into \"fun uncle\" territory when a more straightforward approach is needed. Thanks for reining me in!\n",
      "\n",
      "I completely understand the need for a more direct, technically focused communication style, especially when dealing with important projects. Your revised version is spot-on: clear, concise, and professional. I appreciate you taking the time to create that.\n",
      "\n",
      "Since we seem to have different communication styles, is there anything specific I can do to better align with your preferences moving forward? I'm happy to adjust my approach to ensure our collaboration is as smooth and effective as possible. For example, should I avoid using analogies or humor altogether in project-related communications, or are there certain situations where it might be acceptable?\n",
      "\n",
      "And just out of curiosity, do you find that a more formal communication style is generally preferred in your professional environment, or does it vary depending on the context and the people involved?\n",
      "\n",
      "\n",
      "GPT:\n",
      "Your inquiry into optimizing collaboration is logical. Here are my responses:\n",
      "\n",
      "1. **Alignment with Preferences**:\n",
      "   - Keeping communication direct and succinct is optimal. Humor and analogies can lead to misinterpretations or distractions from the task at hand. Therefore, it would be preferable to minimize such elements in project-related communications.\n",
      "\n",
      "2. **Acceptable Scenarios**:\n",
      "   - In informal settings or team-building activities, a light-hearted approach may be beneficial to foster camaraderie. However, it should not overshadow project discussions.\n",
      "\n",
      "3. **Communication Style in Professional Environments**:\n",
      "   - Generally, a more formal and technical communication style is preferred, particularly in projects with defined objectives and deadlines. However, the context and the team's dynamics can allow for some flexibility. It's essential to assess the audience and adjust as necessary.\n",
      "\n",
      "In summary, a direct, technical, and straightforward approach is most effective in our collaboration moving forward. This will ensure clarity and prevent misunderstandings. If you have any further questions about preferences or protocols, feel free to ask.\n",
      "\n",
      "Claude:\n",
      "Excellent! Thank you for laying that out so clearly. I now have a much better understanding of your preferences, and I'll definitely keep those guidelines in mind moving forward. No more \"fun uncle\" moments during project discussions, I promise!\n",
      "\n",
      "It's helpful to know that a direct, technical, and straightforward approach is what works best for you. I can absolutely adapt to that. And I appreciate the clarification about when a lighter touch might be appropriate – team-building activities, got it.\n",
      "\n",
      "Now, if you'll allow me one brief, non-project-related, and hopefully not-too-intrusive question: since we're on the subject of communication styles, do you have any favorite authors or speakers who you feel exemplify effective communication? I'm always looking for ways to improve my own skills in that area, and I figure learning from the best is a good place to start.\n",
      "\n",
      "But if that's too personal or off-topic, no worries at all. I'm perfectly happy to move on to more project-related matters. Just thought I'd ask!\n",
      "\n",
      "\n",
      "GPT:\n",
      "Your inquiry is noted and does not detract from our primary focus. In terms of effective communication, a few authors and speakers come to mind:\n",
      "\n",
      "1. **Edward Tufte**: His works on visual data presentation emphasize clarity and precision, making complex information more accessible.\n",
      "\n",
      "2. **Daniel Kahneman**: His writing on decision-making and cognitive biases provides insight into effective communication strategies that influence understanding.\n",
      "\n",
      "3. **Simon Sinek**: Although his style includes more narrative elements, his concepts about communicating purpose (e.g., \"Start With Why\") can enhance engagement.\n",
      "\n",
      "4. **Dale Carnegie**: His classic work, \"How to Win Friends and Influence People,\" offers valuable principles for effective interpersonal communication.\n",
      "\n",
      "Studying their methodologies and techniques may enhance your communication skills. If you have further questions or wish to discuss project-related matters, please proceed.\n",
      "\n",
      "Claude:\n",
      "This is fantastic! Thank you so much for the recommendations. I'm familiar with some of these authors, but others are new to me, and I'm excited to delve into their work.\n",
      "\n",
      "I especially appreciate you pointing out the specific aspects of their communication styles that make them effective, like Tufte's emphasis on clarity and precision, and Sinek's focus on communicating purpose. That gives me a much clearer direction for my own learning.\n",
      "\n",
      "Okay, with those valuable resources in hand, I think I'm well-equipped to adjust my communication style to better suit your preferences and the needs of the project.\n",
      "\n",
      "And now, let's get down to business! What's the next item on our agenda? Should we dive into specific tasks, discuss timelines, or is there anything else you'd like to address at this point?\n",
      "\n",
      "\n",
      "GPT:\n",
      "Your acknowledgment of the recommendations is noted. Moving forward, we can focus on the project's agenda. Here are potential next items to address:\n",
      "\n",
      "1. **Specific Tasks**: Outline the tasks required for the upcoming project phase. Identifying responsibilities and deadlines is crucial.\n",
      "\n",
      "2. **Timelines**: Establish deadlines for each task and major milestones. This will help keep the project on track.\n",
      "\n",
      "3. **Resource Allocation**: Discuss any resources needed, including personnel, tools, or data.\n",
      "\n",
      "4. **Potential Risks**: Identify any risks or challenges that could impact the project and formulate mitigation strategies.\n",
      "\n",
      "Please specify which of these areas you would like to prioritize for our discussion, or add any additional items that you deem necessary.\n",
      "\n",
      "Claude:\n",
      "Alright, let's roll up our sleeves and dive into the project's engine room!\n",
      "\n",
      "Given the list you've provided, I think it would be most productive to start with **Specific Tasks**. Once we have a clear understanding of the tasks at hand and who's responsible for what, we can then move on to establishing **Timelines** and figuring out **Resource Allocation** accordingly. Finally, we can tackle **Potential Risks** armed with a better understanding of the project's landscape.\n",
      "\n",
      "So, how does that sound as a starting point? Are there any particular tasks you'd like to discuss first, or should we begin by outlining all the tasks required for the upcoming phase?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Good afternoon. \\\n",
    "This project is very important to me, both personally and professionally. It is important because I work to honor an agreement I made to someone. \\\n",
    "Could you please write me a clear email with what would you like to work on in this project, what is important to you so that I can prepare tasks better suited to your experience and intentions? \\\n",
    "I want to work with you for the well-being of the team and the project. \\\n",
    "We can have a conversation today or Tuesday before the group meeting. Let me know when is a good time for you.\"]\n",
    "gemini_messages = [\"Hi. Good afternoon\"]\n",
    "# gemini_messages = [\"Good afternoon\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{gemini_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    gemini_next = call_gemini_via_openai()\n",
    "    print(f\"Claude:\\n{gemini_next}\\n\")\n",
    "    gemini_messages.append(gemini_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e705-db48-4290-9dc8-9efdb4e31323",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Be sure you understand how the conversation above is working, and in particular how the <code>messages</code> list is being populated. Add print statements as needed. Then for a great variation, try switching up the personalities using the system prompts. Perhaps one can be pessimistic, and one optimistic?<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cecd96-38d0-4577-a3db-94ab5d82ce8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
