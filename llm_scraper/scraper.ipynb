{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3673c2a9-30a4-4b13-a2ca-c0fc7df787cc",
   "metadata": {},
   "source": [
    "## This script - \n",
    "- reads a list of URLs from a file, \n",
    "- scrapes the text content from each URL, \n",
    "- and uses the OpenAI API to summarize the content into structured activity data. \n",
    "- The output is saved as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8945f-19d7-49e7-94ea-b066af514067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18b6ad-e45b-42c4-9e62-af11803af91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your OpenAI API key\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1bcfc-e08c-4067-9166-e7723d524eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e40bd-30e3-4650-ba63-febe86635a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    \"\"\"Scrape text content from a website\"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        text = \" \".join([p.get_text() for p in soup.find_all(\"p\")])\n",
    "        return text.strip()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d32e8-82c3-4470-9da0-fdb904f3f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_content(content):\n",
    "    \"\"\"Use OpenAI API to summarize content into structured activity data\"\"\"\n",
    "    if not content:\n",
    "        return None\n",
    "    \n",
    "    prompt = f\"Extract main activities from the following text and categorize them as 'sports', 'leisure', or 'culture'. Format the output as a JSON list of objects with 'name' and 'type'.\\n\\nText: {content}\\n\\nJSON:\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL_GPT,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "            # temperature=0.5,\n",
    "        )\n",
    "        # summary = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        summary = response.choices[0].message.content\n",
    "        return json.loads(summary) if summary else None\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748dc82-f79b-47f9-b1b0-5f284d267654",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"urls.txt\"\n",
    "output_file = \"summaries.json\"\n",
    "\n",
    "try:\n",
    "    with open(input_file, \"r\") as file:\n",
    "        print(\"Reading input file complete\")\n",
    "        urls = [line.strip() for line in file if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {input_file} not found.\")\n",
    "    # return\n",
    "    exit\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"Processing {url}...\")\n",
    "    content = scrape_website(url)\n",
    "    if content:\n",
    "        activities = summarize_content(content)\n",
    "        if activities:\n",
    "            results.append({\"url\": url, \"data\": {\"activities\": activities}})\n",
    "\n",
    "        print(f\"Result of processing {results}\")\n",
    "    time.sleep(2)  # Avoid rate limits\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump({\"result\": results}, file, indent=4)\n",
    "\n",
    "print(f\"Summaries saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
